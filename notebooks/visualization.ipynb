{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize test performance with Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import NTUDataset, get_train_val_set\n",
    "from model import ConvLSTM\n",
    "\n",
    "\n",
    "def get_train_val_loader(params, val_pct=0.2):\n",
    "    train_samples, val_samples = get_train_val_set(data_path=params.data_path, val_pct=val_pct, temporal_aug_k=params.temporal_aug_k)\n",
    "    print(f'Train samples: {len(train_samples)} || Validation samples: {len(val_samples)}')\n",
    "    \n",
    "    # Apply transform to normalize the data\n",
    "    # transform = transforms.Normalize((0.5), (0.5))\n",
    "    \n",
    "    # Load train and validation dataset\n",
    "    train_set = NTUDataset(sample_set=train_samples, params=params, transform=None)\n",
    "    val_set = NTUDataset(sample_set=val_samples, params=params, transform=None)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=params.BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=params.BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def save_model(model):\n",
    "    current_time = datetime.now()\n",
    "    current_time = current_time.strftime(\"%m_%d_%Y_%H_%M\")\n",
    "    torch.save(model.state_dict(), f'../saved_models/ntu_lstm_{current_time}.pth')\n",
    "    \n",
    "    \n",
    "def build_test_stats(preds, actual, acc, params):\n",
    "    print(f'Model accuracy: {acc}')\n",
    "    \n",
    "    # For confusion matrix\n",
    "    preds = [int(k) for k in preds]\n",
    "    actual = [int(k) for k in actual]\n",
    "\n",
    "    cf = confusion_matrix(actual, preds, labels=list(range(params.num_classes)))\n",
    "    return cf\n",
    "\n",
    "\n",
    "def train(model, train_loader, loss_function, optimizer, params):\n",
    "    print('Training...')\n",
    "    for epoch in range(params.n_epochs):\n",
    "        for batch in tqdm(train_loader):\n",
    "            inputs, labels = batch[0].to(device).float(), batch[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {epoch} | Loss: {loss}')\n",
    "\n",
    "    return model\n",
    "\n",
    "def test(model, test_loader):\n",
    "    print('Testing...')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    preds = []\n",
    "    actual = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device)\n",
    "            class_outputs = model(inputs)\n",
    "            _, class_prediction = torch.max(class_outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (class_prediction == labels).sum().item()\n",
    "            preds.extend(list(class_prediction.to(dtype=torch.int64)))\n",
    "            actual.extend(list(labels.to(dtype=torch.int64)))\n",
    "\n",
    "    acc = 100*correct/total\n",
    "    return preds, actual, acc\n",
    "\n",
    "\n",
    "def main(params):\n",
    "    # Initialize some variables to track progress\n",
    "    accs = []\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = ConvLSTM(params=params).to(device)\n",
    "    \n",
    "    # Use parallel computing if available\n",
    "    if device.type == 'cuda' and n_gpus > 1:\n",
    "        model = nn.DataParallel(model, list(range(n_gpus)))\n",
    "        \n",
    "    # Loss Function and Optimizer (can use weight=class_weights if it is a disbalanced dataset)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Get train and validation loaders\n",
    "    train_loader, val_loader = get_train_val_loader(params, val_pct=0.2)\n",
    "    \n",
    "    # Train the model\n",
    "    model = train(model, train_loader, loss_function, optimizer, params)\n",
    "    save_model(model)\n",
    "\n",
    "    # Get training accuracy\n",
    "    preds, actual, acc = test(model, train_loader)\n",
    "    build_test_stats(preds, actual, acc, params)\n",
    "    \n",
    "    # Validate the model\n",
    "    preds, actual, acc = test(model, val_loader)\n",
    "    build_test_stats(preds, actual, acc, params)\n",
    "    \n",
    "\n",
    "## Optional code to load and test a model\n",
    "def load_test_model(params, model_path):\n",
    "    model = ConvLSTM(params=params).to(device)\n",
    "    # Use this to fix keyError in the model when using DataParallel while training\n",
    "    if device.type == 'cuda' and n_gpus > 1:\n",
    "        model = nn.DataParallel(model, list(range(n_gpus)))\n",
    "    train_loader, val_loader = get_train_val_loader(params, val_pct=0.2)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval() # To set dropout and batchnormalization OFF\n",
    "    preds, actual, acc = test(model, val_loader)\n",
    "    return build_test_stats(preds, actual, acc, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 2\n"
     ]
    }
   ],
   "source": [
    "params = {'mode': 'inference', 'model_path': '../saved_models/ntu_lstm_01_27_2021_15_53.pth', 'kp_shape': [25, 3], 'seg_size': 50, \n",
    "          'data_path': '/data/zak/graph/ntu/train', \n",
    "          'BATCH_SIZE': 8, 'temporal_aug_k': 3, 'k_fold': 1, 'n_epochs': 8, 'num_classes': 120, 'bcc': 32, 'num_channels': 1,\n",
    "          'num_joints': 25, 'num_coord': 3}\n",
    "params = edict(params)\n",
    "# Check for GPUs\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpus = torch.cuda.device_count()\n",
    "print(f'Number of GPUs available: {n_gpus}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'model_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-17b6949b7649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'model_path'"
     ]
    }
   ],
   "source": [
    "cf = load_test_model(params, model_path=params.model_path)\n",
    "df_cm = pd.DataFrame(cf, index=[str(i) for i in range(1, 121)], columns=[str(i) for i in range(1, 121)])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu",
   "language": "python",
   "name": "ntu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
