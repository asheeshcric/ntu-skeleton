{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NTU RGB-D 120 data path\n",
    "\n",
    "data_dir = '/data/zak/graph/ntu/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The train directory contains video samples from 120 classes with around 114480 samples (some might be missing though)\n",
    "* Each file name is in the following format:\n",
    "    - `S013C003P037R001A004.skeleton.npy`\n",
    "    - S013 stands for **Setup Number 13**\n",
    "    - C003 stands for **Camera Number 03**\n",
    "    - P037 stands for **Participant Number 037**\n",
    "    - R001 stands for **Replication Number (001 or 002 only) << need to find out what this means**\n",
    "    - A004 stands for **Action Class Number 004 (brush hair in this case)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design data loader for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A list of parameters that can be changed for the dataloader with their default values\n",
    "- kp_shape = (25,3)\n",
    "- seg_size = varies based on the action being performed (so, select a minimum segment size among all samples in the dataset)\n",
    "    - min_seg_size in the dataset is 15, so need to pad the segment with its earlier frames if seg_size is greater than it\n",
    "- participant_list <= those who are in the train or validation or test set (a list of numbers/codes for the participants)\n",
    "- data_path = '/data/zak/graph/ntu/train'\n",
    "- BATCH_SIZE <== For the model\n",
    "- temporal_aug_k <== Defines number of random samples from one segment (for temporal augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTUDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_path, sample_set, kp_shape=(25, 3), seg_size=40):\n",
    "        # Initialize all parameters for the model\n",
    "        self.sample_set = sample_set\n",
    "        self.kp_shape = kp_shape\n",
    "        self.seg_size = seg_size\n",
    "        self.data_path = data_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Number of samples in the dataset\n",
    "        return len(self.sample_set)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return a particular item from the dataset\n",
    "        sample_name = self.sample_set[idx]\n",
    "        sample_path = os.path.join(self.data_path, sample_name)\n",
    "        \n",
    "        # Process the sample into tensor keypoints for the given index\n",
    "        sample_kp, action_class = self.read_sample(sample_path, sample_name)\n",
    "        \n",
    "        return sample_kp, action_class\n",
    "    \n",
    "    # ----- Helper functions -----\n",
    "    def read_sample(self, sample_path, sample_name):\n",
    "        data = np.load(sample_path, allow_pickle=True).item()\n",
    "        # Each data sample has the following keys:\n",
    "        # dict_keys(['file_name', 'nbodys', 'njoints', 'skel_body0', 'rgb_body0', 'depth_body0', 'skel_body1', 'rgb_body1', 'depth_body1'])\n",
    "        # For now, I am just considering one participant for each video segment and taking 'skel_body0' as input keypoints\n",
    "        kps = self.augment_kp(data['skel_body0'])\n",
    "        action_class = int(sample_name.split('A')[1][:3])\n",
    "        return kps, action_class\n",
    "    \n",
    "    def augment_kp(self, sample_kp):\n",
    "        # Temporally augment video segment based on the minimum segment size for the dataset\n",
    "        # Randomly take \"seg_size\" number of frames from the segment (in chronological order)\n",
    "        sample_size = sample_kp.shape[0]\n",
    "        if sample_size < self.seg_size:\n",
    "            # Pad same frames at the end in order to meet the segment size requirement\n",
    "            return self.pad_frames(torch.tensor(sample_kp))\n",
    "        rand_segments = sorted(random.sample(range(0, sample_size), self.seg_size))\n",
    "        sample_kp = torch.tensor(np.take(sample_kp, rand_segments, axis=0))\n",
    "        return sample_kp\n",
    "    \n",
    "    def pad_frames(self, sample_kp):\n",
    "        # Consider seg_size for the dataset is 40 and the current sample has only 15 frames in the segment\n",
    "        # We will need to repeat the frames in order to make it reach 40\n",
    "        padded_kp = sample_kp\n",
    "        sample_size = sample_kp.shape[0]\n",
    "        additional_frames = self.seg_size - sample_size\n",
    "        while additional_frames >= sample_size:\n",
    "            padded_kp = torch.cat((padded_kp, sample_kp), dim=0)\n",
    "            additional_frames -= sample_size\n",
    "            \n",
    "        padded_kp = torch.cat((padded_kp, sample_kp[:additional_frames]))\n",
    "        return padded_kp\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions for Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# samples file_name = 'S018C001P042R002A120.skeleton.npy'\n",
    "# P042 is the participant number\n",
    "# Remember that I am trying to split the dataset based on the participants and not the total samples\n",
    "# This means that the validation set will have samples from all unique participants that are not involved in the train set\n",
    "\n",
    "def get_participant_number(file_name):\n",
    "    return file_name.split('P')[1][:3]\n",
    "\n",
    "def split_participants(data_path, val_pct=0.2):\n",
    "    # Returns a random list of participants for the train and validation sets respectively\n",
    "    samples = os.listdir(data_path)\n",
    "    total_samples = len(samples)\n",
    "    # Get all unique participant numbers\n",
    "    all_participants = set()\n",
    "    for sample in samples:\n",
    "        part = get_participant_number(sample)\n",
    "        all_participants.add(part)\n",
    "    total_participants = len(all_participants)\n",
    "    all_participants = list(all_participants)\n",
    "    \n",
    "    # Split into train and val sets\n",
    "    val_len = int(total_participants * val_pct)\n",
    "    # Randomly shuffle the list\n",
    "    random.shuffle(list(all_participants))\n",
    "    train_participants = all_participants[val_len:]\n",
    "    val_participants = all_participants[:val_len]\n",
    "\n",
    "    print(f'Total Video Samples: {len(samples)} || Total Participants: {len(all_participants)} || Train Participants: {len(train_participants)} || Validation Participants: {len(val_participants)}')\n",
    "    return train_participants, val_participants\n",
    "\n",
    "def get_train_val_set(data_path, val_pct=0.2, temporal_aug_k=3):\n",
    "    train_participants, val_participants = split_participants(data_path, val_pct)\n",
    "    train_samples, val_samples = [], []\n",
    "    # min_seg_size = 1000\n",
    "    for sample in os.listdir(data_path):\n",
    "        participant_number = get_participant_number(sample)\n",
    "        # Temporary code to check the minimum segment size in the dataset\n",
    "        # data = np.load(os.path.join(data_path, sample), allow_pickle=True).item()['skel_body0']\n",
    "        # min_seg_size = min(min_seg_size, data.shape[0])\n",
    "        \n",
    "        # Apply data augmentation here ('k' times random temporal augmentation)\n",
    "        for _ in range(temporal_aug_k):\n",
    "            if participant_number in val_participants:\n",
    "                val_samples.append(sample)\n",
    "            else:\n",
    "                train_samples.append(sample)\n",
    "    \n",
    "    # print(f'Minimum segment size in the dataset: {min_seg_size}')\n",
    "    return train_samples, val_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Video Samples: 114460 || Total Participants: 106 || Train Participants: 85 || Validation Participants: 21\n",
      "Train samples: 290466 || Validation samples: 52914\n"
     ]
    }
   ],
   "source": [
    "train_samples, val_samples = get_train_val_set(data_path=data_dir, val_pct=0.2)\n",
    "print(f'Train samples: {len(train_samples)} || Validation samples: {len(val_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train dataset\n",
    "train_set = NTUDataset(data_path=data_dir, sample_set=train_samples)\n",
    "val_set = NTUDataset(data_path=data_dir, sample_set=val_samples)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 40, 25, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([76, 85, 72, 28, 85, 53,  5, 37])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu",
   "language": "python",
   "name": "ntu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
